{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDMOGlyHbDt7tAkIDUD2Zb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wendemsky/direct_s2s_translation/blob/main/direct_s2s_translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB5VV6S1m1bG",
        "outputId": "1b22f029-619f-490b-822e-1ca458565cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.3.2-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2023.7.22)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required module for text\n",
        "# to speech conversion\n",
        "from gtts import gTTS\n",
        "\n",
        "# This module is imported so that we can\n",
        "# play the converted audio\n",
        "import os\n",
        "\n",
        "# Function to convert text to speech and save as mp3\n",
        "def text_to_speech(input_file, language, output_folder):\n",
        "    # Read the text from the input file\n",
        "    with open(input_file, 'r', encoding='utf-8') as file:\n",
        "        sentences = file.readlines()\n",
        "\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    # Convert each sentence to audio\n",
        "    for index, sentence in enumerate(sentences):\n",
        "        sentence = sentence.strip()\n",
        "        if sentence:\n",
        "            # Create a gTTS object\n",
        "            tts = gTTS(text=sentence, lang=language, slow=False)\n",
        "\n",
        "            # Save the audio file\n",
        "            audio_file = os.path.join(output_folder, f\"{index+1}.mp3\")\n",
        "            tts.save(audio_file)\n",
        "\n",
        "            print(f\"Converted and saved: {audio_file}\")\n",
        "\n",
        "# Language for English and Korean\n",
        "english_language = 'en'\n",
        "korean_language = 'ko'\n",
        "\n",
        "# Input and output folders\n",
        "english_input_file = 'english_text.txt'\n",
        "korean_input_file = 'korean_text.txt'\n",
        "english_output_folder = 'english_audio'\n",
        "korean_output_folder = 'korean_audio'\n",
        "\n",
        "# Convert English text to audio\n",
        "text_to_speech(english_input_file, english_language, english_output_folder)\n",
        "\n",
        "# Convert Korean text to audio\n",
        "text_to_speech(korean_input_file, korean_language, korean_output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS5HsMDOm2xi",
        "outputId": "41534b0f-ad44-4f0b-c3da-587c0f2e7672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted and saved: english_audio/1.mp3\n",
            "Converted and saved: english_audio/2.mp3\n",
            "Converted and saved: english_audio/3.mp3\n",
            "Converted and saved: english_audio/4.mp3\n",
            "Converted and saved: english_audio/5.mp3\n",
            "Converted and saved: english_audio/6.mp3\n",
            "Converted and saved: english_audio/7.mp3\n",
            "Converted and saved: english_audio/8.mp3\n",
            "Converted and saved: english_audio/9.mp3\n",
            "Converted and saved: english_audio/10.mp3\n",
            "Converted and saved: english_audio/11.mp3\n",
            "Converted and saved: english_audio/12.mp3\n",
            "Converted and saved: english_audio/13.mp3\n",
            "Converted and saved: english_audio/14.mp3\n",
            "Converted and saved: english_audio/15.mp3\n",
            "Converted and saved: english_audio/16.mp3\n",
            "Converted and saved: english_audio/17.mp3\n",
            "Converted and saved: english_audio/18.mp3\n",
            "Converted and saved: english_audio/19.mp3\n",
            "Converted and saved: english_audio/20.mp3\n",
            "Converted and saved: english_audio/21.mp3\n",
            "Converted and saved: english_audio/22.mp3\n",
            "Converted and saved: english_audio/23.mp3\n",
            "Converted and saved: english_audio/24.mp3\n",
            "Converted and saved: english_audio/25.mp3\n",
            "Converted and saved: english_audio/26.mp3\n",
            "Converted and saved: english_audio/27.mp3\n",
            "Converted and saved: english_audio/28.mp3\n",
            "Converted and saved: english_audio/29.mp3\n",
            "Converted and saved: english_audio/30.mp3\n",
            "Converted and saved: english_audio/31.mp3\n",
            "Converted and saved: english_audio/32.mp3\n",
            "Converted and saved: english_audio/33.mp3\n",
            "Converted and saved: english_audio/34.mp3\n",
            "Converted and saved: english_audio/35.mp3\n",
            "Converted and saved: english_audio/36.mp3\n",
            "Converted and saved: english_audio/37.mp3\n",
            "Converted and saved: english_audio/38.mp3\n",
            "Converted and saved: english_audio/39.mp3\n",
            "Converted and saved: english_audio/40.mp3\n",
            "Converted and saved: english_audio/41.mp3\n",
            "Converted and saved: english_audio/42.mp3\n",
            "Converted and saved: english_audio/43.mp3\n",
            "Converted and saved: english_audio/44.mp3\n",
            "Converted and saved: english_audio/45.mp3\n",
            "Converted and saved: english_audio/46.mp3\n",
            "Converted and saved: english_audio/47.mp3\n",
            "Converted and saved: english_audio/48.mp3\n",
            "Converted and saved: english_audio/49.mp3\n",
            "Converted and saved: english_audio/50.mp3\n",
            "Converted and saved: korean_audio/1.mp3\n",
            "Converted and saved: korean_audio/2.mp3\n",
            "Converted and saved: korean_audio/3.mp3\n",
            "Converted and saved: korean_audio/4.mp3\n",
            "Converted and saved: korean_audio/5.mp3\n",
            "Converted and saved: korean_audio/6.mp3\n",
            "Converted and saved: korean_audio/7.mp3\n",
            "Converted and saved: korean_audio/8.mp3\n",
            "Converted and saved: korean_audio/9.mp3\n",
            "Converted and saved: korean_audio/10.mp3\n",
            "Converted and saved: korean_audio/11.mp3\n",
            "Converted and saved: korean_audio/12.mp3\n",
            "Converted and saved: korean_audio/13.mp3\n",
            "Converted and saved: korean_audio/14.mp3\n",
            "Converted and saved: korean_audio/15.mp3\n",
            "Converted and saved: korean_audio/16.mp3\n",
            "Converted and saved: korean_audio/17.mp3\n",
            "Converted and saved: korean_audio/18.mp3\n",
            "Converted and saved: korean_audio/19.mp3\n",
            "Converted and saved: korean_audio/20.mp3\n",
            "Converted and saved: korean_audio/21.mp3\n",
            "Converted and saved: korean_audio/22.mp3\n",
            "Converted and saved: korean_audio/23.mp3\n",
            "Converted and saved: korean_audio/24.mp3\n",
            "Converted and saved: korean_audio/25.mp3\n",
            "Converted and saved: korean_audio/26.mp3\n",
            "Converted and saved: korean_audio/27.mp3\n",
            "Converted and saved: korean_audio/28.mp3\n",
            "Converted and saved: korean_audio/29.mp3\n",
            "Converted and saved: korean_audio/30.mp3\n",
            "Converted and saved: korean_audio/31.mp3\n",
            "Converted and saved: korean_audio/32.mp3\n",
            "Converted and saved: korean_audio/33.mp3\n",
            "Converted and saved: korean_audio/34.mp3\n",
            "Converted and saved: korean_audio/35.mp3\n",
            "Converted and saved: korean_audio/36.mp3\n",
            "Converted and saved: korean_audio/37.mp3\n",
            "Converted and saved: korean_audio/38.mp3\n",
            "Converted and saved: korean_audio/39.mp3\n",
            "Converted and saved: korean_audio/40.mp3\n",
            "Converted and saved: korean_audio/41.mp3\n",
            "Converted and saved: korean_audio/42.mp3\n",
            "Converted and saved: korean_audio/43.mp3\n",
            "Converted and saved: korean_audio/44.mp3\n",
            "Converted and saved: korean_audio/45.mp3\n",
            "Converted and saved: korean_audio/46.mp3\n",
            "Converted and saved: korean_audio/47.mp3\n",
            "Converted and saved: korean_audio/48.mp3\n",
            "Converted and saved: korean_audio/49.mp3\n",
            "Converted and saved: korean_audio/50.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change the file names on both the folders from 1.mp3 to 50.mp3"
      ],
      "metadata": {
        "id": "VW_cu5Z9zCwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "\n",
        "# # def rename_mp3_files(folder_path):\n",
        "# #     files = os.listdir(folder_path)\n",
        "# #     mp3_files = [f for f in files if f.lower().endswith('.mp3')]\n",
        "\n",
        "# #     print(f'Folder path: {folder_path}')\n",
        "# #     print(f'All files in the folder: {files}')\n",
        "# #     print(f'MP3 files found: {len(mp3_files)}')\n",
        "\n",
        "# #     for index, mp3_file in enumerate(mp3_files, start=1):\n",
        "# #         old_path = os.path.join(folder_path, mp3_file)\n",
        "# #         new_path = os.path.join(folder_path, f'{index}.mp3')\n",
        "# #         os.rename(old_path, new_path)\n",
        "# #         print(f'Renamed {old_path} to {new_path}')\n",
        "\n",
        "\n",
        "# # if __name__ == \"__main__\":\n",
        "# #     folder_path_en = r'/content/english_audio'  # Change this to your mp3 file folder\n",
        "# #     folder_path_kr = r'/content/korean_audio'\n",
        "# #     rename_mp3_files(folder_path_en)\n",
        "# #     rename_mp3_files(folder_path_kr)\n",
        "# #     print(\"MP3 files renamed successfully!\")\n"
      ],
      "metadata": {
        "id": "CekqnOmxygW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "\n",
        "# Paths to audio folders\n",
        "english_audio_folder = 'english_audio'\n",
        "korean_audio_folder = 'korean_audio'\n",
        "english_text_file = 'english_text.txt'\n",
        "korean_text_file = 'korean_text.txt'\n",
        "\n",
        "# Read the English and Korean text files\n",
        "with open(english_text_file, 'r', encoding='utf-8') as eng_file, \\\n",
        "     open(korean_text_file, 'r', encoding='utf-8') as kor_file:\n",
        "    english_translations = eng_file.readlines()\n",
        "    korean_translations = kor_file.readlines()\n",
        "\n",
        "# Ensure the audio and text lists match\n",
        "if len(english_translations) != len(korean_translations):\n",
        "    raise ValueError(\"Number of audio files and translations don't match!\")\n",
        "\n",
        "# Create a list to hold dataset entries\n",
        "dataset = []\n",
        "\n",
        "# Walk through the English audio folder\n",
        "for root, _, files in os.walk(english_audio_folder):\n",
        "    for file in files:\n",
        "        if file.endswith('.mp3'):\n",
        "            # Create the file paths for English and Korean audio\n",
        "            english_audio_path = os.path.join(root, file)\n",
        "            korean_audio_path = os.path.join(korean_audio_folder, file)\n",
        "\n",
        "            # Get the corresponding translations\n",
        "            index = int(file.split('.')[0]) - 1\n",
        "            english_translation = english_translations[index].strip()\n",
        "            korean_translation = korean_translations[index].strip()\n",
        "\n",
        "            dataset.append([english_audio_path, english_translation, korean_audio_path, korean_translation])\n",
        "\n",
        "# Save the dataset to a CSV file\n",
        "with open('speech_to_speech_dataset.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile)\n",
        "    csv_writer.writerow(['audio_path_english', 'translation_english', 'audio_path_korean', 'translation_korean'])\n",
        "    csv_writer.writerows(dataset)\n"
      ],
      "metadata": {
        "id": "ozeAp4FM1saq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning - Data cleaning procedures were not necessary for this project as the dataset comprises only 50 audio files. Each audio file and its corresponding text translation were manually reviewed to ensure data quality and consistency."
      ],
      "metadata": {
        "id": "3O8yq9982x8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Loading\n",
        "\n",
        "Now, We Load the dataset from the CSV file."
      ],
      "metadata": {
        "id": "nwWJ2sOq-zDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the path to your CSV file containing the dataset\n",
        "csv_file_path = 'speech_to_speech_dataset.csv'  # Replace with the actual file path\n",
        "\n",
        "# Load the dataset into a Pandas DataFrame\n",
        "dataset = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Split the dataset into training, validation, and testing sets\n",
        "# Using train_test_split from scikit-learn for proper random splitting\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "train_dataset, test_val_dataset = train_test_split(dataset, test_size=(1 - train_ratio))\n",
        "val_dataset, test_dataset = train_test_split(test_val_dataset, test_size=test_ratio / (test_ratio + val_ratio))\n",
        "\n",
        "# Verify the sizes of the splits\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of validation samples: {len(val_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GQHwI4z3fE6",
        "outputId": "7886f720-b013-4cd6-caf2-680f6592301e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 40\n",
            "Number of validation samples: 5\n",
            "Number of testing samples: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "id": "3xwfc4HdEtJm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cd3d64-ed4b-47fa-84e1-186440334827"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing\n",
        "\n",
        "Now that we have loaded the data successfully, We will now preprocess the data.\n"
      ],
      "metadata": {
        "id": "VxYUqBqqBIhd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import librosa\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Paths to the audio folders and the CSV dataset file\n",
        "# english_audio_folder = 'english_audio'\n",
        "# korean_audio_folder = 'korean_audio'\n",
        "# dataset_file = 'speech_to_speech_dataset.csv'\n",
        "\n",
        "# # Load the dataset from the CSV file\n",
        "# dataset = pd.read_csv(dataset_file)\n",
        "\n",
        "# # Define the maximum sequence length for audio and text (adjust as needed)\n",
        "# max_audio_length = 100  # You can change this value based on your model's requirements\n",
        "# max_seq_length = 50  # Define your desired sequence length for text data\n",
        "\n",
        "# # Initialize lists to store audio features and text data\n",
        "# X_audio = []\n",
        "# X_text = []\n",
        "# Y_text = []\n",
        "\n",
        "# # Initialize tokenizers for text data\n",
        "# english_tokenizer = Tokenizer()\n",
        "# korean_tokenizer = Tokenizer()\n",
        "\n",
        "# # Extract MFCC features from audio and tokenize text\n",
        "# sample_rate = 22050  # Define the sample rate (adjust as needed)\n",
        "\n",
        "# # Function to plot MFCC features\n",
        "# def plot_mfcc(mfcc):\n",
        "#     plt.figure(figsize=(10, 4))\n",
        "#     plt.imshow(mfcc, cmap='viridis', origin='lower', aspect='auto')\n",
        "#     plt.title('MFCC Features')\n",
        "#     plt.xlabel('Time')\n",
        "#     plt.ylabel('MFCC Coefficients')\n",
        "#     plt.colorbar(format='%+2.0f dB')\n",
        "#     plt.show()\n",
        "\n",
        "# # Function to plot MFCC coefficients\n",
        "# def plot_mfcc_coefficients(mfcc):\n",
        "#     plt.figure(figsize=(8, 4))\n",
        "#     plt.plot(mfcc)\n",
        "#     plt.title('MFCC Coefficients')\n",
        "#     plt.xlabel('Frame')\n",
        "#     plt.ylabel('Amplitude')\n",
        "#     plt.grid()\n",
        "#     plt.show()\n",
        "\n",
        "# for index, row in dataset.iterrows():\n",
        "#     # Load and preprocess audio\n",
        "#     audio_path = os.path.join(english_audio_folder, os.path.basename(row['audio_path_english']))\n",
        "#     signal, _ = librosa.load(audio_path, sr=sample_rate)\n",
        "#     mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=13, hop_length=512, n_fft=2048)\n",
        "#     mfccs = pad_sequences([mfccs.T], maxlen=max_audio_length, padding='post')[0]  # Padding/truncating\n",
        "\n",
        "#     # Plot an example MFCC\n",
        "#     if index == 0:\n",
        "#         plot_mfcc(mfccs)\n",
        "#         # Print an example of MFCC coefficients for the first sample\n",
        "#         print(\"Example MFCC coefficients for the first sample:\")\n",
        "#         print(mfccs)\n",
        "\n",
        "#     # Tokenize and encode English and Korean text\n",
        "#     english_text = row['translation_english']\n",
        "#     korean_text = row['translation_korean']\n",
        "#     english_seq = english_tokenizer.texts_to_sequences([english_text])[0]\n",
        "#     korean_seq = korean_tokenizer.texts_to_sequences([korean_text])[0]\n",
        "\n",
        "#     # Append to lists\n",
        "#     X_audio.append(mfccs)\n",
        "#     X_text.append(english_seq)  # Using English as input text\n",
        "#     Y_text.append(korean_seq)  # Using Korean as target text\n",
        "\n",
        "# # Convert lists to numpy arrays\n",
        "# X_audio = np.array(X_audio)\n",
        "# X_text = pad_sequences(X_text, maxlen=max_seq_length, padding='post')\n",
        "# Y_text = pad_sequences(Y_text, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# # Define the path for the new CSV file containing preprocessed data\n",
        "# preprocessed_csv_file = 'preprocessed_speech_to_speech_dataset.csv'\n",
        "\n",
        "# # Save the preprocessed data to the new CSV file\n",
        "# preprocessed_dataset = pd.DataFrame({'audio_path_english': dataset['audio_path_english'],\n",
        "#                                      'translation_english': dataset['translation_english'],\n",
        "#                                      'audio_path_korean': dataset['audio_path_korean'],\n",
        "#                                      'translation_korean': dataset['translation_korean'],\n",
        "#                                      'mfcc_features': list(X_audio),\n",
        "#                                      'english_sequence': X_text.tolist(),  # Convert to list\n",
        "#                                      'korean_sequence': Y_text.tolist()})  # Convert to list\n",
        "\n",
        "# preprocessed_dataset.to_csv(preprocessed_csv_file, index=False, encoding='utf-8')\n",
        "\n",
        "# print(\"Preprocessed dataset saved to:\", preprocessed_csv_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "id": "a0L2B-2KBU_c",
        "outputId": "b7914882-4f7f-4067-ffe4-02bdabd749b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example MFCC coefficients for the first sample:\n",
            "[[-591    0    0 ...    0    0    0]\n",
            " [-480   75  -13 ...   -4    2    2]\n",
            " [-270  138  -20 ...  -14    0    0]\n",
            " ...\n",
            " [-592    0    0 ...    0    0    0]\n",
            " [-592    0    0 ...    0    0    0]\n",
            " [-592    0    0 ...    0    0    0]]\n",
            "Preprocessed dataset saved to: preprocessed_speech_to_speech_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKz2bXxuzXms",
        "outputId": "47d69eb7-8b24-444f-ad1f-3326f4f2cdfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import librosa\n",
        "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Paths to the audio folders and the CSV dataset file\n",
        "# english_audio_folder = 'english_audio'\n",
        "# korean_audio_folder = 'korean_audio'\n",
        "# dataset_file = 'speech_to_speech_dataset.csv'\n",
        "\n",
        "# # Load the dataset from the CSV file\n",
        "# dataset = pd.read_csv(dataset_file)\n",
        "\n",
        "# # Define the maximum sequence length for audio and text (adjust as needed)\n",
        "# max_audio_length = 100  # You can change this value based on your model's requirements\n",
        "# max_seq_length = 50  # Define your desired sequence length for text data\n",
        "\n",
        "# # Initialize lists to store audio features and text data\n",
        "# X_audio = []\n",
        "# X_text = []\n",
        "# Y_text = []\n",
        "\n",
        "# # Initialize tokenizers for text data\n",
        "# english_tokenizer = Tokenizer()\n",
        "# korean_tokenizer = Tokenizer()\n",
        "\n",
        "# # Extract MFCC features from audio and tokenize text\n",
        "# sample_rate = 22050  # Define the sample rate (adjust as needed)\n",
        "\n",
        "# # Function to plot MFCC features\n",
        "# def plot_mfcc(mfcc):\n",
        "#     plt.figure(figsize=(10, 4))\n",
        "#     plt.imshow(mfcc, cmap='viridis', origin='lower', aspect='auto')\n",
        "#     plt.title('MFCC Features')\n",
        "#     plt.xlabel('Time')\n",
        "#     plt.ylabel('MFCC Coefficients')\n",
        "#     plt.colorbar(format='%+2.0f dB')\n",
        "#     plt.show()\n",
        "\n",
        "# # Function to plot MFCC coefficients\n",
        "# def plot_mfcc_coefficients(mfcc):\n",
        "#     plt.figure(figsize=(8, 4))\n",
        "#     plt.plot(mfcc)\n",
        "#     plt.title('MFCC Coefficients')\n",
        "#     plt.xlabel('Frame')\n",
        "#     plt.ylabel('Amplitude')\n",
        "#     plt.grid()\n",
        "#     plt.show()\n",
        "\n",
        "# # Split the dataset into training and validation sets\n",
        "# train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Preprocess each sample in the training dataset\n",
        "# for index, row in train_dataset.iterrows():\n",
        "#     # Load and preprocess audio\n",
        "#     audio_path = os.path.join(english_audio_folder, os.path.basename(row['audio_path_english']))\n",
        "#     signal, _ = librosa.load(audio_path, sr=sample_rate)\n",
        "#     mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=13, hop_length=512, n_fft=2048)\n",
        "#     mfccs = pad_sequences([mfccs.T], maxlen=max_audio_length, padding='post')[0]  # Padding/truncating\n",
        "\n",
        "#     # Tokenize and encode English and Korean text\n",
        "#     english_text = row['translation_english']\n",
        "#     korean_text = row['translation_korean']\n",
        "#     english_seq = english_tokenizer.texts_to_sequences([english_text])[0]\n",
        "#     korean_seq = korean_tokenizer.texts_to_sequences([korean_text])[0]\n",
        "\n",
        "#     # Append to lists\n",
        "#     X_audio.append(mfccs)\n",
        "#     X_text.append(english_seq)  # Using English as input text\n",
        "#     Y_text.append(korean_seq)  # Using Korean as target text\n",
        "\n",
        "# # Convert lists to numpy arrays\n",
        "# X_audio = np.array(X_audio)\n",
        "# X_text = pad_sequences(X_text, maxlen=max_seq_length, padding='post')\n",
        "# Y_text = pad_sequences(Y_text, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# # Define the path for the new CSV file containing preprocessed data\n",
        "# preprocessed_csv_file = 'preprocessed_speech_to_speech_dataset.csv'\n",
        "\n",
        "# # Save the preprocessed data to the new CSV file\n",
        "# preprocessed_dataset = pd.DataFrame({'audio_path_english': train_dataset['audio_path_english'],\n",
        "#                                      'translation_english': train_dataset['translation_english'],\n",
        "#                                      'audio_path_korean': train_dataset['audio_path_korean'],\n",
        "#                                      'translation_korean': train_dataset['translation_korean'],\n",
        "#                                      'mfcc_features': list(X_audio),\n",
        "#                                      'english_sequence': X_text.tolist(),  # Convert to list\n",
        "#                                      'korean_sequence': Y_text.tolist()})  # Convert to list\n",
        "\n",
        "# preprocessed_dataset.to_csv(preprocessed_csv_file, index=False, encoding='utf-8')\n",
        "\n",
        "# print(\"Preprocessed dataset saved to:\", preprocessed_csv_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHB-6cqWylvq",
        "outputId": "d6a96223-049f-40b6-f465-c8376cfedb05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed dataset saved to: preprocessed_speech_to_speech_dataset.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import load_model  # Import the function to load the model\n",
        "\n",
        "# Paths to the audio folders and the CSV dataset file\n",
        "english_audio_folder = 'english_audio'\n",
        "korean_audio_folder = 'korean_audio'\n",
        "dataset_file = 'speech_to_speech_dataset.csv'\n",
        "\n",
        "# Load the dataset from the CSV file\n",
        "dataset = pd.read_csv(dataset_file)\n",
        "\n",
        "# Define the maximum sequence length for audio and text (adjust as needed)\n",
        "max_audio_length = 100\n",
        "max_seq_length = 50\n",
        "\n",
        "# Initialize lists to store audio features and text data\n",
        "X_audio = []\n",
        "X_text = []\n",
        "Y_text = []\n",
        "\n",
        "# Initialize tokenizers for text data\n",
        "english_tokenizer = Tokenizer()\n",
        "korean_tokenizer = Tokenizer()\n",
        "\n",
        "# Extract MFCC features from audio and tokenize text\n",
        "sample_rate = 22050\n",
        "\n",
        "# Function to plot MFCC features\n",
        "def plot_mfcc(mfcc):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.imshow(mfcc, cmap='viridis', origin='lower', aspect='auto')\n",
        "    plt.title('MFCC Features')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('MFCC Coefficients')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.show()\n",
        "\n",
        "# Function to plot MFCC coefficients\n",
        "def plot_mfcc_coefficients(mfcc):\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.plot(mfcc)\n",
        "    plt.title('MFCC Coefficients')\n",
        "    plt.xlabel('Frame')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "# Split the dataset into training and validation sets\n",
        "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "# Preprocess each sample in the validation dataset\n",
        "X_val_audio = []\n",
        "X_val_text = []\n",
        "Y_val_text = []\n",
        "\n",
        "for index, row in val_dataset.iterrows():\n",
        "    # Load and preprocess audio (similar to the training data preprocessing)\n",
        "    audio_path = os.path.join(english_audio_folder, os.path.basename(row['audio_path_english']))\n",
        "    signal, _ = librosa.load(audio_path, sr=sample_rate)\n",
        "    mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=13, hop_length=512, n_fft=2048)\n",
        "    mfccs = pad_sequences([mfccs.T], maxlen=max_audio_length, padding='post')[0]\n",
        "\n",
        "    # Tokenize and encode English and Korean text (similar to the training data preprocessing)\n",
        "    english_text = row['translation_english']\n",
        "    korean_text = row['translation_korean']\n",
        "    english_seq = english_tokenizer.texts_to_sequences([english_text])[0]\n",
        "    korean_seq = korean_tokenizer.texts_to_sequences([korean_text])[0]\n",
        "\n",
        "    # Append to validation lists\n",
        "    X_val_audio.append(mfccs)\n",
        "    X_val_text.append(english_seq)\n",
        "    Y_val_text.append(korean_seq)\n",
        "\n",
        "# Convert validation lists to numpy arrays\n",
        "X_val_audio = np.array(X_val_audio)\n",
        "X_val_text = pad_sequences(X_val_text, maxlen=max_seq_length, padding='post')\n",
        "Y_val_text = pad_sequences(Y_val_text, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "# Load the trained model\n",
        "model = load_model('speech_to_speech_translation_model.h5')  # Replace with your model's filename\n",
        "\n",
        "# Evaluate the model on the validation dataset\n",
        "val_loss, val_accuracy = model.evaluate([X_val_audio, X_val_text], Y_val_text, verbose=1)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_accuracy)\n",
        "\n",
        "# Now, you can proceed with inference using the loaded model\n",
        "# ...\n",
        "\n",
        "# For example, to perform inference on a single input:\n",
        "# audio_input = ...  # Load and preprocess a single audio input\n",
        "# text_input = ...   # Tokenize and preprocess the corresponding text input\n",
        "# inference_result = model.predict([audio_input, text_input])\n",
        "# ...\n",
        "\n",
        "# Save the trained model if needed\n",
        "# model.save('speech_to_speech_translation_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1emKnkdY2su-",
        "outputId": "58ba902f-9d5d-46a1-9847-17f2f30791a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step - loss: 0.0000e+00 - accuracy: 0.0000e+00\n",
            "Validation Loss: 0.0\n",
            "Validation Accuracy: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before moving on to the model phase, let's check the shapes and data to ensure everything is in order."
      ],
      "metadata": {
        "id": "r6ncWcAsunAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shapes of the preprocessed data\n",
        "print(\"X_audio shape:\", X_audio.shape)\n",
        "print(\"X_text shape:\", X_text.shape)\n",
        "print(\"Y_text shape:\", Y_text.shape)\n",
        "\n",
        "# Check a sample of the preprocessed data\n",
        "print(\"Sample of X_audio:\")\n",
        "print(X_audio[0])  # Print the first sample as an example\n",
        "\n",
        "print(\"Sample of X_text:\")\n",
        "print(X_text[0])  # Print the first sample as an example\n",
        "\n",
        "print(\"Sample of Y_text:\")\n",
        "print(Y_text[0])  # Print the first sample as an example\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFJ-AZCXugUS",
        "outputId": "187751f8-e6ee-4c5a-8685-4b1b8d54ab44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_audio shape: (40, 100, 13)\n",
            "X_text shape: (40, 50)\n",
            "Y_text shape: (40, 50)\n",
            "Sample of X_audio:\n",
            "[[-389  118   22 ...   -7    0  -15]\n",
            " [-427   52   -1 ...   -2   -7    3]\n",
            " [-289   47  -33 ...    2    6    8]\n",
            " ...\n",
            " [-589    0    0 ...    0    0    0]\n",
            " [-589    0    0 ...    0    0    0]\n",
            " [-589    0    0 ...    0    0    0]]\n",
            "Sample of X_text:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Sample of Y_text:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In data preprocessing, we transformed our bilingual audio-text dataset. We extracted audio features (MFCCs) and tokenized and encoded text, creating a well-structured dataset ready for training our speech translation model."
      ],
      "metadata": {
        "id": "1klZdIEWEaNC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "eU9q0WOzVxP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tT2t2xHpCB3v",
        "outputId": "d59e12d2-e203-46c5-ffea-0861390bcd8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.13.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.57.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: keras<2.14,>=2.13.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.14,>=2.13 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.13.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define the model architecture\n",
        "latent_dim = 256  # Adjust this value as needed\n",
        "\n",
        "# Define input layers\n",
        "audio_input = Input(shape=(max_audio_length, 13))\n",
        "text_input = Input(shape=(max_seq_length,))\n",
        "\n",
        "# Define embedding layers for text data\n",
        "# Use the same embedding layer for both source and target text\n",
        "embedding_layer = Embedding(input_dim=len(english_tokenizer.word_index) + 1, output_dim=latent_dim)\n",
        "\n",
        "text_embedding = embedding_layer(text_input)\n",
        "\n",
        "# Define the encoder LSTM\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(audio_input)\n",
        "\n",
        "# Connect encoder and decoder\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(text_embedding, initial_state=[state_h, state_c])\n",
        "\n",
        "# Define the output layer\n",
        "output_layer = Dense(len(korean_tokenizer.word_index) + 1, activation='softmax')\n",
        "output = output_layer(decoder_outputs)\n",
        "\n",
        "# Define the model\n",
        "model = Model([audio_input, text_input], output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()\n",
        "\n",
        "# Prepare target sequences for training\n",
        "Y_train = pad_sequences(Y_text, maxlen=max_seq_length, padding='post')\n",
        "Y_train = to_categorical(Y_train, num_classes=len(korean_tokenizer.word_index) + 1)\n",
        "\n",
        "# Train the model\n",
        "model.fit([X_audio, X_text], Y_train, batch_size=64, epochs=50, validation_split=0.2)\n",
        "\n",
        "# Save the trained model if needed\n",
        "# model.save('speech_to_speech_translation_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkdkuowTvDeT",
        "outputId": "056f460e-64e4-4227-c543-9e33cf98fe03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_12 (InputLayer)       [(None, 50)]                 0         []                            \n",
            "                                                                                                  \n",
            " input_11 (InputLayer)       [(None, 100, 13)]            0         []                            \n",
            "                                                                                                  \n",
            " embedding_7 (Embedding)     (None, 50, 256)              256       ['input_12[0][0]']            \n",
            "                                                                                                  \n",
            " lstm_10 (LSTM)              [(None, 256),                276480    ['input_11[0][0]']            \n",
            "                              (None, 256),                                                        \n",
            "                              (None, 256)]                                                        \n",
            "                                                                                                  \n",
            " lstm_11 (LSTM)              [(None, 50, 256),            525312    ['embedding_7[0][0]',         \n",
            "                              (None, 256),                           'lstm_10[0][1]',             \n",
            "                              (None, 256)]                           'lstm_10[0][2]']             \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 50, 1)                257       ['lstm_11[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 802305 (3.06 MB)\n",
            "Trainable params: 802305 (3.06 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 8s 8s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 1s 588ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 1s 699ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 1s 911ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 1s 851ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 1s 639ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 1s 831ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 1s 873ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 1s 947ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 1s 953ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 1s 806ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 1s 578ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 1s 645ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 1s 594ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 1s 599ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 1s 686ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 1s 593ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 1s 600ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 1s 579ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 1s 931ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 1s 964ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 1s 722ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 1s 602ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 1s 687ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 1s 642ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 1s 571ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 1s 584ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 1s 601ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 1s 630ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 1s 585ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 1s 593ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 1s 649ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 1s 640ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 1s 942ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 1s 976ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 1s 935ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bfa44700430>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the trained model in the native Keras format\n",
        "model.save('speech_to_speech_translation_model.keras')\n"
      ],
      "metadata": {
        "id": "pkVuB2vp1acv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "# Load the saved model\n",
        "model = keras.models.load_model('speech_to_speech_translation_model.keras')\n"
      ],
      "metadata": {
        "id": "CjE4n7r1002y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_audio shape:\", X_audio.shape)\n",
        "print(\"X_text shape:\", X_text.shape)\n",
        "print(\"Y_val shape:\", Y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3Q1ltT6xIYL",
        "outputId": "566994fc-37db-41c5-faa3-6475714999e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_audio shape: (50, 100, 13)\n",
            "X_text shape: (50, 50)\n",
            "Y_val shape: (5, 50, 125, 125)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the validation data\n"
      ],
      "metadata": {
        "id": "XWp1Lm-QwJfz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation data\n",
        "metrics = model.evaluate([X_audio, X_text], Y_val)\n",
        "\n",
        "# Extract and print relevant metrics\n",
        "loss = metrics[0]\n",
        "accuracy = metrics[1]\n",
        "\n",
        "print(\"Validation Loss:\", loss)\n",
        "print(\"Validation Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "B63hnci7wJwi",
        "outputId": "ba3620fc-f8af-4c7a-db2a-e961ef5c4767"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-8378ef5bb7cb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluate the model on the validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_audio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Extract and print relevant metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1948\u001b[0m             )\n\u001b[1;32m   1949\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1950\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 50, 50\n  y sizes: 5\nMake sure all arrays contain the same number of samples."
          ]
        }
      ]
    }
  ]
}